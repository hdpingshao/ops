### 平均负责

###### 每次发现系统变慢时，我们通常做的第一件事，就是执行top或者uptime命令，来了解系统的负载情况。比如像下面这样，我们在命令行里输入了uptime命令，系统也随即给出了结果

	[root@localhost ~]# uptime
	 15:17:18 up 1 day,  5:47,  1 user,  load average: 0.66, 0.88, 0.89
	 
###### 这几列的含义依次是当前时间、系统运行时间、登陆的用户数、过去1分钟、5分钟、15分钟的平均负载（Load average）

###### 下面我们就来学习下，如何观测和理解这个最常见也是最重要的系统指标。

###### 我猜一定有人会说，平均负载不就是单位时间内的CPU使用率么，上面的0.66，就代表CPU使用率是66%。其实并不是这样的，你可以通过执行man uptime命令来了解平均负载的详细解释。

###### 简单来说，平均负载就是志单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和CPU使用率并没有直接关系。这里我先解释下，可运行状态和不可终端状态

- 所谓可运行状态的进程，是指正在使用CPU或者正在等待CPU的进程，也就是我们常用ps命令看到的，处于R状态（Running或Runnable）的进程
- 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的I/O响应，也就是我们在ps命令中看到的D状态（Uninterruptible Sleep，也称为Disk Sleep）的进程

###### 比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它时不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。

###### 所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。

###### 因此，你可以理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。这个“指数衰减平均”的详细含义不用计较，这只是系统的一种更快速的计算方式，你把它直接当成活跃进程数的平均值也没问题。

###### 既然平均的是活跃进程数，那么最理想的，就是每个CPU上都刚好运行着一个进程，这样每个CPU都得到了充分利用。比如当平均负载为2时，意味着什么情况呢？

- 在只有2个CPU的系统上，意味着所有的CPU都刚好被完全占用。
- 在4个CPU系统上，意味着CPU有50%的空闲。
- 而在只有1个CPU的系统中，则意味着有一半的进程竞争不到CPU。

#### 平均负载为多少时合理

###### 我们知道，平均负载最理想的情况是等于CPU个数。所以在评判平均负载时，首先你要知道系统有几个CPU，这可以通过top命令或者从文件/proc/cpuinfo中读取，比如：

	[root@localhost ~]# grep 'model name' /proc/cpuinfo | wc -l
	2

###### 有了CPU个数，我们就可以判断出，当平均负载比CPU个数还大的时候，系统已经出现了过载。不过，新的问题来了。我们在例子中可以看到，平均负载有三个数值，到底该参考哪一个呢。实际上，都要看。三个不同时间间隔的平均值，其实给我们提供了，分析系统负载趋势的数据来源，让我们能更全面、更立体地理解目前的负载状况。

- 如果1分钟、5分钟、15分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。
- 如果1分钟的值远小于15分钟的值，就说明系统最近1分钟的负载在减少，而过去15分钟内却又很大的负载
- 反过来，如果1分钟的值远大于15分钟的值，就说明系统最近1分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦1分钟的平均负载接近或者超过了CPU的个数，就意味着系统正在发生过载的问题，这时就得分析调查时哪里导致的问题，并要想办法优化了。

###### 举个例子，假设我们在一个单CPU系统上看到平均负载为1.77，0.66，7.88，那么说明在过去1分钟内，系统有77%的超载，而在15分钟内，有688%的超载，从整体趋势来看，系统的负载在降低。

###### 那么，在实际生产环境中，平均负载多高时，需要我们重点关注呢？

###### 在我看来，当平均负载高于CPU数量70%的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。

###### 但是70%这个数字并不是绝对的最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，再去做分析和调查。

#### 平均负载与CPU使用率

###### 现实工作中，我们经常容易把平均负载和CPU使用率混淆，这边我们来做个区分。

###### 可能你会疑惑，既然平均负载代表的时活跃进程数，那平均负载高了，不久意味着CPU使用率高吗？

###### 我们还是要回到平均负载的含义上来，平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用CPU的进程，还包括等待CPU和等待I/O的进程。

###### 而CPU使用率，是单位时间内CPU繁忙情况的统计，跟平均负载并不一定完全对应。比如：

- CPU密集型的进程，使用大量CPU会导致平均负载升高，此时这两者是一致的；
- I/O密集型进程，等待I/O也会导致平均负载升高，单CPU使用率不一定很高；
- 大量等待CPU的进程调度也会导致平均负载升高，此时的CPU使用率也会比较高。

#### 平均负载案例分析

###### 接下来，我们以三个示例分别来看这三种情况，并用iostat、mpstat、pidstat等工具，找出平均负载升高的根源。

###### 预先在linux系统上安装好stress和sysstat包，如yum install -y stress sysstat

###### 简单介绍以下stress和sysstat。

###### stress是一个linux系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。

###### sysstat包含了常用的linux性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令mpstat和pidstat。

- mpstat是一个常用的多核CPU性能分析工具，用来实时查看每个CPU的性能指标，以及所有CPU的平均指标。
- pidstat是一个常用的进程性能分析工具，用来实时查看进程的CPU、内存、I/O以及上下文切换等性能指标。

###### 接下来可以使用uptime命令，看一下测试前的平均负载情况：

	[root@localhost ~]# uptime
	 15:17:18 up 1 day,  5:47,  1 user,  load average: 0.00, 0.01, 0.05
	 
#### 场景一：CPU密集型进程

###### 首先，我们在终端运行stress命令，模拟一个CPU使用率100%的场景：

    stress --cpu 1 --timeout 600

###### 接着，再开一个终端运行uptime查看平均负载的变化情况：

	# -d 参数表示高亮显示变化的区域
	watch -d uptime
	...,  load average: 1.00, 0.75, 0.39

###### 最后，再开一个终端运行mpstat查看CPU使用率的变化情况：

	# -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
	mpstat -P ALL 5
	Linux 3.10.0-514.2.2.el7.x86_64 (localhost.localdomain)         12/26/2018      _x86_64_        (2 CPU)
	04:07:48 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
	04:07:53 PM  all   50.10    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   49.90
	04:07:53 PM    0   39.20    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   60.60
	04:07:53 PM    1   61.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   39.00

###### 从第二个终端中可以看到，1分钟的平均负载会慢慢的增加到1.00，而从第三个终端中还可以看到，所以CPU的使用率为50%，但是它们的iowait都为0.这说明，平均负载的升高正是由于CPU使用率的升高引起的。

###### 那么，到底是哪个进程导致了CPU使用率的升高呢，这边可以使用pidstat来查询：

    # 间隔 5 秒后输出一组数据
	[root@localhost ~]# pidstat -u 5 1
	Linux 3.10.0-514.2.2.el7.x86_64 (localhost.localdomain)         12/26/2018      _x86_64_        (2 CPU)

	04:14:40 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
	04:14:45 PM     0      5290  100.00    0.00    0.00  100.00     1  stress

	Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
	Average:        0      5290  100.00    0.00    0.00  100.00     -  stress

###### 从这里可以明显看到，stress进程的CPU使用率为100%

#### 场景二：I/O密集型进程

###### 首先还是运行stress命令，但这次模拟I/O压力，即不停地执行sync：

    stress -i 1 --timeout 600
    
###### 还是在第二个终端运行uptime查看平均负载的变化情况：

	watch -d uptime
	...,  load average: 1.06, 0.58, 0.37

###### 然后，在第三个终端运行mpstat查看CPU使用率的变化情况：

	# 显示所有 CPU 的指标，并在间隔 5 秒输出一组数据
	mpstat -P ALL 5 1
	Linux 4.15.0 (ubuntu)     09/22/18     _x86_64_    (2 CPU)
	13:41:28     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
	13:41:33     all    0.21    0.00   12.07   32.67    0.00    0.21    0.00    0.00    0.00   54.84
	13:41:33       0    0.43    0.00   23.87   67.53    0.00    0.43    0.00    0.00    0.00    7.74
	13:41:33       1    0.00    0.00    0.81    0.20    0.00    0.00    0.00    0.00    0.00   98.99

###### 从这里可以看到，1分钟的平均负载会慢慢增加到1.06，CPU的系统CPU使用率升高到23.87，而iowait高达67.53%。这说明，平均负载的升高时由于iowait的升高。

###### 那么到底是哪个进程，导致iowait这么高的呢？我们还是用pidstat来查询：

	# 间隔 5 秒后输出一组数据，-u 表示 CPU 指标
	[root@localhost ~]# pidstat -u 5 1
	Linux 3.10.0-514.2.2.el7.x86_64 (localhost.localdomain)         12/26/2018      _x86_64_        (2 CPU)

	04:36:47 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
	04:36:52 PM     0      4719    0.00    0.20    0.00    0.20     1  watch
	04:36:52 PM     0      5657    0.00    1.40    0.00    1.40     0  kworker/u4:0
	04:36:52 PM     0      6058    0.00    3.60    0.00    3.60     1  kworker/u4:2
	04:36:52 PM     0      6551    0.00   96.80    0.00   96.80     1  stress

	Average:      UID       PID    %usr %system  %guest    %CPU   CPU  Command
	Average:        0      4719    0.00    0.20    0.00    0.20     -  watch
	Average:        0      5657    0.00    1.40    0.00    1.40     -  kworker/u4:0
	Average:        0      6058    0.00    3.60    0.00    3.60     -  kworker/u4:2
	Average:        0      6551    0.00   96.80    0.00   96.80     -  stress

###### 可以发现，还是stress进程导致的。

#### 场景三：大量进程的场景

######当系统中运行进程超出CPU运行能力时，就会出现等待CPU的进程

###### 比如，我们还是使用stress，单这次模拟的时8个进程：

    stress -c 8 --timeout 600
    
###### 由于系统只有2个CPU，明显比8个进程要少得多，因而，系统的CPU处于严重过载状态，平均负载高达7.83：

	uptime
	...,  load average: 7.83, 5.93, 3.02
	
###### 接着在运行pidstat来看以下进程的情况：

	# 间隔 5 秒后输出一组数据
	pidstat -u 5 1
	14:23:25      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
	14:23:30        0      3190   25.00    0.00    0.00   74.80   25.00     0  stress
	14:23:30        0      3191   25.00    0.00    0.00   75.20   25.00     0  stress
	14:23:30        0      3192   25.00    0.00    0.00   74.80   25.00     1  stress
	14:23:30        0      3193   25.00    0.00    0.00   75.00   25.00     1  stress
	14:23:30        0      3194   24.80    0.00    0.00   74.60   24.80     0  stress
	14:23:30        0      3195   24.80    0.00    0.00   75.00   24.80     0  stress
	14:23:30        0      3196   24.80    0.00    0.00   74.60   24.80     1  stress
	14:23:30        0      3197   24.80    0.00    0.00   74.80   24.80     1  stress
	14:23:30        0      3200    0.00    0.20    0.00    0.20    0.20     0  pidstat

###### 可以看出，8个进程在争抢2个CPU，每个进程等待CPU的时间（也就是代码块中%wait列）高达75%。这些超出CPU计算能力的进程，最终导致CPU过载。

#### 小结

###### 分析完这三个案例，我们再来归纳以下平均负载的理解。

###### 平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底时哪里出现了瓶颈。所以，在理解平均负载时，也要注意：

- 平均负载高有可能是CPU密集型进程导致的；
- 平均负载高并不一定代表CPU使用率高，还有可能是I/O更繁忙了；
- 当返现负载高的时候，你可以使用mpstat、pidstat等工具，辅助分析负载的来源。

#### 实验过程出现问题的补充：

- 1、iowait无法升高的问题，是因为案例中stress使用的是 sync()系统调用，它的作用是刷新缓冲区内存到磁盘中。对于新安装的虚拟机，缓冲区可能比较小，无法产生大的IO压力，这样大部分就都是系统调用的消耗了。所以，你会看到只有系统CPU使用率升高。解决方法是使用stress的下一代stress-ng，它支持更丰富的选项，比如 stress-ng -i 1 --hdd 1 --timeout 600（--hdd表示读写临时文件）。
- 2、pidstat输出中没有%wait的问题，是因为CentOS默认的sysstat稍微有点老，源码或者RPM升级到11.5.5版本以后就可以看到了。
- 3、mpstat无法观测的问题，案例中是等待5秒后输出1次结果就停止了，更好的做法是持续监控一段时间，比如持续观测20次：mpstat -P ALL 5 20。